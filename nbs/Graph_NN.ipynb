{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph-NN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "H9Rwatasfevc",
        "FopBJgee1B_J"
      ],
      "authorship_tag": "ABX9TyO/xBLHCoa6i/GvltdhK/mO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marcosuff/Marcosuff.github.io/blob/master/nbs/Graph_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wRir1JzgKSY"
      },
      "source": [
        "#export\n",
        "%%capture\n",
        "import sys\n",
        "!pip install -U fastai \n",
        "#! wget -c https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh\n",
        "#! bash Anaconda3-2019.10-Linux-x86_64.sh -bfp /usr/local\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages')\n",
        "!conda install -y -c rdkit rdkit"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apVFLB1rhpIY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.rdchem import BondType\n",
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "\n",
        "from torch.utils import data\n",
        "from collections import defaultdict\n",
        "\n",
        "from fastai.learner import *\n",
        "from fastai.data.core import *\n",
        "from fastai.text.all import *\n",
        "from fastai.data.core import DataLoader\n",
        "\n",
        "import os\n",
        "from os.path import join\n",
        "from google.colab import drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDYAS-x9gfau",
        "outputId": "f3bbc47b-6cd5-4fe2-845f-f8ed381fcbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df  = pd.read_csv('/content/fxa_ic50_processed.csv',sep=';')\n",
        "df.head(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>standard_value</th>\n",
              "      <th>standard_type</th>\n",
              "      <th>standard_relation</th>\n",
              "      <th>pchembl</th>\n",
              "      <th>molregno</th>\n",
              "      <th>canonical_smiles</th>\n",
              "      <th>chembl_id</th>\n",
              "      <th>target_dictionary</th>\n",
              "      <th>target_chembl_id</th>\n",
              "      <th>l1</th>\n",
              "      <th>l2</th>\n",
              "      <th>l3</th>\n",
              "      <th>confidence_score</th>\n",
              "      <th>act</th>\n",
              "      <th>processed_smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3476</td>\n",
              "      <td>44.4</td>\n",
              "      <td>IC50</td>\n",
              "      <td>=</td>\n",
              "      <td>7.35</td>\n",
              "      <td>192068</td>\n",
              "      <td>N=C(N)N1CCC[C@H](NC(=O)CNC(=O)[C@@H](CCNC(=O)c2ccc3ccccc3n2)NS(=O)(=O)Cc2ccccc2)C1O</td>\n",
              "      <td>CHEMBL117716</td>\n",
              "      <td>194</td>\n",
              "      <td>CHEMBL244</td>\n",
              "      <td>Enzyme</td>\n",
              "      <td>Protease</td>\n",
              "      <td>Serine protease</td>\n",
              "      <td>8</td>\n",
              "      <td>Active</td>\n",
              "      <td>N=C(N)N1CCC[C@H](NC(=O)CNC(=O)[C@@H](CCNC(=O)c2ccc3ccccc3n2)NS(=O)(=O)Cc2ccccc2)C1O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6512</td>\n",
              "      <td>180.0</td>\n",
              "      <td>IC50</td>\n",
              "      <td>=</td>\n",
              "      <td>6.75</td>\n",
              "      <td>203908</td>\n",
              "      <td>Cc1cc(NC(=O)Cc2ccc3[nH]c(-c4ccc(Cl)s4)nc3c2)ccc1-n1ccccc1=O</td>\n",
              "      <td>CHEMBL337921</td>\n",
              "      <td>194</td>\n",
              "      <td>CHEMBL244</td>\n",
              "      <td>Enzyme</td>\n",
              "      <td>Protease</td>\n",
              "      <td>Serine protease</td>\n",
              "      <td>8</td>\n",
              "      <td>Active</td>\n",
              "      <td>Cc1cc(NC(=O)Cc2ccc3[nH]c(-c4ccc(Cl)s4)nc3c2)ccc1-n1ccccc1=O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   doc_id  ...                                                                     processed_smiles\n",
              "0    3476  ...  N=C(N)N1CCC[C@H](NC(=O)CNC(=O)[C@@H](CCNC(=O)c2ccc3ccccc3n2)NS(=O)(=O)Cc2ccccc2)C1O\n",
              "1    6512  ...                          Cc1cc(NC(=O)Cc2ccc3[nH]c(-c4ccc(Cl)s4)nc3c2)ccc1-n1ccccc1=O\n",
              "\n",
              "[2 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9Rwatasfevc"
      },
      "source": [
        "# Chemprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVhUgHgTWcz7"
      },
      "source": [
        "Chemprop is a Directed-Message Passing Neural network. I'll probably try to reimplement it from scratch using fastai.\n",
        "\n",
        "You can find the original code and installation guide here:\n",
        "https://github.com/chemprop/chemprop#option-1-installing-from-pypi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxldO_PEhuoD"
      },
      "source": [
        "#!chemprop_train --data_path data.csv --smiles_column Smiles --target_columns pXC50 --dataset_type regression --save_dir ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvzR5DMGfhLJ"
      },
      "source": [
        "# Prototype GCNN - MPNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IIbhwIfUC5b"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FopBJgee1B_J"
      },
      "source": [
        "### **Features (atoms and bonds features are one-hot encoded)** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLWXso1AgNSx",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#export\n",
        "#https://github.com/Marcosuff/graph-neural-networks-for-drug-discovery/blob/master/gnn/molgraph_data.py\n",
        "def one_of_k_encoding(x, allowable_set):\n",
        "  if x not in allowable_set:\n",
        "    raise Exception(\"input {0} not in allowable set{1}:\".format(\n",
        "        x, allowable_set))\n",
        "  return list(map(lambda s: x == s, allowable_set))\n",
        "\n",
        "\n",
        "def one_of_k_encoding_unk(x, allowable_set):\n",
        "  \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
        "  if x not in allowable_set:\n",
        "    x = allowable_set[-1]\n",
        "  return list(map(lambda s: x == s, allowable_set))\n",
        "\n",
        "\n",
        "def get_intervals(l):\n",
        "  \"\"\"For list of lists, gets the cumulative products of the lengths\"\"\"\n",
        "  intervals = len(l) * [0]\n",
        "  # Initalize with 1\n",
        "  intervals[0] = 1\n",
        "  for k in range(1, len(l)):\n",
        "    intervals[k] = (len(l[k]) + 1) * intervals[k - 1]\n",
        "\n",
        "  return intervals\n",
        "\n",
        "\n",
        "def safe_index(l, e):\n",
        "  \"\"\"Gets the index of e in l, providing an index of len(l) if not found\"\"\"\n",
        "  try:\n",
        "    return l.index(e)\n",
        "  except:\n",
        "    return len(l)\n",
        "\n",
        "\n",
        "possible_atom_list = [\n",
        "    'C', 'N', 'O', 'S', 'F', 'P', 'Cl', 'Mg', 'Na', 'Br', 'Fe', 'Ca', 'Cu',\n",
        "    'Mc', 'Pd', 'Pb', 'K', 'I', 'Al', 'Ni', 'Mn'\n",
        "]\n",
        "possible_numH_list = [0, 1, 2, 3, 4]\n",
        "possible_valence_list = [0, 1, 2, 3, 4, 5, 6]\n",
        "possible_formal_charge_list = [-3, -2, -1, 0, 1, 2, 3]\n",
        "possible_hybridization_list = [\n",
        "    Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
        "    Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D,\n",
        "    Chem.rdchem.HybridizationType.SP3D2\n",
        "]\n",
        "possible_number_radical_e_list = [0, 1, 2]\n",
        "possible_chirality_list = ['R', 'S']\n",
        "\n",
        "reference_lists = [\n",
        "    possible_atom_list, possible_numH_list, possible_valence_list,\n",
        "    possible_formal_charge_list, possible_number_radical_e_list,\n",
        "    possible_hybridization_list, possible_chirality_list\n",
        "]\n",
        "\n",
        "intervals = get_intervals(reference_lists)\n",
        "\n",
        "\n",
        "def get_feature_list(atom):\n",
        "  features = 6 * [0]\n",
        "  features[0] = safe_index(possible_atom_list, atom.GetSymbol())\n",
        "  features[1] = safe_index(possible_numH_list, atom.GetTotalNumHs())\n",
        "  features[2] = safe_index(possible_valence_list, atom.GetImplicitValence())\n",
        "  features[3] = safe_index(possible_formal_charge_list, atom.GetFormalCharge())\n",
        "  features[4] = safe_index(possible_number_radical_e_list,\n",
        "                           atom.GetNumRadicalElectrons())\n",
        "  features[5] = safe_index(possible_hybridization_list, atom.GetHybridization())\n",
        "  return features\n",
        "\n",
        "\n",
        "def features_to_id(features, intervals):\n",
        "  \"\"\"Convert list of features into index using spacings provided in intervals\"\"\"\n",
        "  id = 0\n",
        "  for k in range(len(intervals)):\n",
        "    id += features[k] * intervals[k]\n",
        "\n",
        "  # Allow 0 index to correspond to null molecule 1\n",
        "  id = id + 1\n",
        "  return id\n",
        "\n",
        "\n",
        "def atom_to_id(atom):\n",
        "  \"\"\"Return a unique id corresponding to the atom type\"\"\"\n",
        "  features = get_feature_list(atom)\n",
        "  return features_to_id(features, intervals)\n",
        "\n",
        "\n",
        "def atom_features(atom,\n",
        "                  bool_id_feat=False,\n",
        "                  explicit_H=False,\n",
        "                  use_chirality=False):\n",
        "  if bool_id_feat:\n",
        "    return np.array([atom_to_id(atom)])\n",
        "  else:\n",
        "    results = one_of_k_encoding_unk(\n",
        "      atom.GetSymbol(),\n",
        "      [\n",
        "        'C',\n",
        "        'N',\n",
        "        'O',\n",
        "        'S',\n",
        "        'F',\n",
        "        'Si',\n",
        "        'P',\n",
        "        'Cl',\n",
        "        'Br',\n",
        "        'Mg',\n",
        "        'Na',\n",
        "        'Ca',\n",
        "        'Fe',\n",
        "        'As',\n",
        "        'Al',\n",
        "        'I',\n",
        "        'B',\n",
        "        'V',\n",
        "        'K',\n",
        "        'Tl',\n",
        "        'Yb',\n",
        "        'Sb',\n",
        "        'Sn',\n",
        "        'Ag',\n",
        "        'Pd',\n",
        "        'Co',\n",
        "        'Se',\n",
        "        'Ti',\n",
        "        'Zn',\n",
        "        'H',  # H?\n",
        "        'Li',\n",
        "        'Ge',\n",
        "        'Cu',\n",
        "        'Au',\n",
        "        'Ni',\n",
        "        'Cd',\n",
        "        'In',\n",
        "        'Mn',\n",
        "        'Zr',\n",
        "        'Cr',\n",
        "        'Pt',\n",
        "        'Hg',\n",
        "        'Pb',\n",
        "        'Unknown'\n",
        "      ]) + one_of_k_encoding(atom.GetDegree(),\n",
        "                             [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) + \\\n",
        "              one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6]) + \\\n",
        "              [atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \\\n",
        "              one_of_k_encoding_unk(atom.GetHybridization(), [\n",
        "                Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
        "                Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.\n",
        "                                    SP3D, Chem.rdchem.HybridizationType.SP3D2\n",
        "              ]) + [atom.GetIsAromatic()]\n",
        "    # In case of explicit hydrogen(QM8, QM9), avoid calling `GetTotalNumHs`\n",
        "    if not explicit_H:\n",
        "      results = results + one_of_k_encoding_unk(atom.GetTotalNumHs(),\n",
        "                                                [0, 1, 2, 3, 4])\n",
        "    if use_chirality:\n",
        "      try:\n",
        "        results = results + one_of_k_encoding_unk(\n",
        "            atom.GetProp('_CIPCode'),\n",
        "            ['R', 'S']) + [atom.HasProp('_ChiralityPossible')]\n",
        "      except:\n",
        "        results = results + [False, False\n",
        "                            ] + [atom.HasProp('_ChiralityPossible')]\n",
        "\n",
        "    return np.array(results)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PESnFyjP1Ncf"
      },
      "source": [
        "### **Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UwIu5bUQQU-",
        "cellView": "both"
      },
      "source": [
        "#export\n",
        "#https://github.com/Marcosuff/graph-neural-networks-for-drug-discovery/blob/master/gnn/molgraph_data.py\n",
        "class MolGraphDataset(data.Dataset):\n",
        "    r\"\"\"For datasets consisting of SMILES strings and target values.\n",
        "    Expects a csv file formatted as:\n",
        "    comment,smiles,targetName1,targetName2\n",
        "    Some Comment,CN=C=O,0,1\n",
        "    ,CC(=O)NCCC1=CNc2c1cc(OC)cc2,1,1\n",
        "    Args:\n",
        "        path\n",
        "        prediction: set to True if dataset contains no target values\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path:str, smiles_col:str='Smiles',target_names:str='pXC50',prediction:bool=False):\n",
        "        #with gzip.open(path, 'r') as file:\n",
        "\n",
        "        self.df = path#pd.read_csv(path)\n",
        "        self.target_names = target_names\n",
        "        self.smiles = self.df[smiles_col].values\n",
        "        self.n_inp = 1 # for fastai\n",
        "\n",
        "        if prediction:\n",
        "            self.targets = self.df[target_names].values\n",
        "        else:\n",
        "            self.targets = self.df[target_names].values\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        adjacency, nodes, edges = smile_to_graph(self.smiles[index])\n",
        "        targets = self.targets[index]\n",
        "        return (adjacency, nodes, edges), targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "rdLogger = rdkit.RDLogger.logger()\n",
        "rdLogger.setLevel(rdkit.RDLogger.ERROR)\n",
        "\n",
        "def smile_to_graph(smile):\n",
        "    molecule = Chem.MolFromSmiles(smile) \n",
        "    n_atoms = molecule.GetNumAtoms() # Number of atoms\n",
        "    atoms = [molecule.GetAtomWithIdx(i) for i in range(n_atoms)] # Get all atoms from molecule\n",
        "\n",
        "    adjacency = Chem.rdmolops.GetAdjacencyMatrix(molecule) # Calculate adjacency matrix (ie., which atom is bonded to which)\n",
        "    node_features = np.array([atom_features(atom) for atom in atoms]) # Bonds features\n",
        "\n",
        "    n_edge_features = 4 # Define bond features (e.g., aromatic, single, double etc)\n",
        "    edge_features = np.zeros([n_atoms, n_atoms, n_edge_features]) # Initialise as zeros\n",
        "    for bond in molecule.GetBonds(): # Compute bond features in a loop\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        bond_type = BONDTYPE_TO_INT[bond.GetBondType()] # Bond type (e.g., aromatic, single, double etc)\n",
        "        edge_features[i, j, bond_type] = 1 # One-hot encoding\n",
        "        edge_features[j, i, bond_type] = 1\n",
        "\n",
        "    return adjacency, node_features, edge_features\n",
        "\n",
        "# rdkit GetBondType() result -> int\n",
        "BONDTYPE_TO_INT = defaultdict(\n",
        "    lambda: 0,\n",
        "    {\n",
        "        BondType.SINGLE: 0,\n",
        "        BondType.DOUBLE: 1,\n",
        "        BondType.TRIPLE: 2,\n",
        "        BondType.AROMATIC: 3\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "class MolGraphDatasetSubset(MolGraphDataset):\n",
        "    r\"\"\"Takes a subset of MolGraphDataset.\n",
        "    The \"Subset\" class of pytorch does not allow column selection\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path, indices=None, columns=None):\n",
        "        super(MolGraphDatasetSubset, self).__init__(path)\n",
        "        if indices:\n",
        "            self.smiles = self.smiles[indices]\n",
        "            self.targets = self.targets[indices]\n",
        "        if columns:\n",
        "            self.target_names = [self.target_names[col] for col in columns]\n",
        "            self.targets = self.targets[:, columns]\n",
        "\n",
        "\n",
        "# data is list of ((g,h,e), [targets])\n",
        "# to be passable to DataLoader it needs to have this signature,\n",
        "# where the outer tuple is that which is returned by Dataset's __getitem__\n",
        "def molgraph_collate_fn(data):\n",
        "    n_samples = len(data)\n",
        "    (adjacency_0, node_features_0, edge_features_0), targets_0 = data[0]\n",
        "    n_nodes_largest_graph = max(map(lambda sample: sample[0][0].shape[0], data))\n",
        "    n_node_features = node_features_0.shape[1]\n",
        "    n_edge_features = edge_features_0.shape[2]\n",
        "    #n_targets = 1#len(targets_0)\n",
        "\n",
        "    adjacency_tensor = torch.zeros(n_samples, n_nodes_largest_graph, n_nodes_largest_graph)\n",
        "    node_tensor = torch.zeros(n_samples, n_nodes_largest_graph, n_node_features)\n",
        "    edge_tensor = torch.zeros(n_samples, n_nodes_largest_graph, n_nodes_largest_graph, n_edge_features)\n",
        "    target_tensor = torch.zeros(n_samples)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        (adjacency, node_features, edge_features), target = data[i]\n",
        "        n_nodes = adjacency.shape[0]\n",
        "\n",
        "        adjacency_tensor[i, :n_nodes, :n_nodes] = torch.Tensor(adjacency)\n",
        "        node_tensor[i, :n_nodes, :] = torch.Tensor(node_features)\n",
        "        edge_tensor[i, :n_nodes, :n_nodes, :] = torch.Tensor(edge_features)\n",
        "        #print(target)\n",
        "        target_tensor[i] = torch.Tensor([target])\n",
        "\n",
        "    return (adjacency_tensor, node_tensor, edge_tensor), target_tensor\n",
        "\n",
        "class CustomDataLoader:\n",
        "    def __init__(self, ds, bs=128, shuffle=False, n_workers=1):\n",
        "        self.ds,self.bs,self.shuffle,self.n_workers = ds,bs,shuffle,n_workers\n",
        "\n",
        "    def __len__(self): return (len(self.ds)-1)//self.bs+1\n",
        "\n",
        "    def __iter__(self):\n",
        "        idxs = L.range(self.ds)\n",
        "        if self.shuffle: idxs = idxs.shuffle()\n",
        "        chunks = [idxs[n:n+self.bs] for n in range(0, len(self.ds), self.bs)]\n",
        "        with ProcessPoolExecutor(self.n_workers) as ex:\n",
        "            yield from ex.map(molgraph_collate_fn, chunks, data=self.ds)    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgGyLnURbiSo"
      },
      "source": [
        "# Create datasets/dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBClhmlNFCHF"
      },
      "source": [
        "cut = int(len(df)*0.8)\n",
        "splits = [list(range(cut)), list(range(cut,len(df)))]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbSsmoiCFfmI"
      },
      "source": [
        "train_df = df.iloc[splits[0]]\n",
        "valid_df = df.iloc[splits[1]]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZqQzJbViP8L"
      },
      "source": [
        "train_ds = MolGraphDataset(train_df,smiles_col='processed_smiles',target_names='pchembl')\n",
        "valid_ds = MolGraphDataset(valid_df,smiles_col='processed_smiles',target_names='pchembl')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEJse2hG3qZ7"
      },
      "source": [
        "train_ds[0][0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXryDaCh8VkC"
      },
      "source": [
        "train_dl =  DataLoader(train_ds, batch_size=64, shuffle=True, create_batch=molgraph_collate_fn)\n",
        "valid_dl =  DataLoader(valid_ds, batch_size=64, shuffle=False, create_batch=molgraph_collate_fn)\n",
        "# To use a custom collate with fastai_v2, we need to pass it in create_batch\n",
        "# https://forums.fast.ai/t/is-there-a-way-to-specify-a-different-collate-fn-for-your-dataloader/68655\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll8i2eW2z5vS"
      },
      "source": [
        "dls = DataLoaders(train_dl,valid_dl)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4uRKsIRYfGn"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iCnIjzHB22t"
      },
      "source": [
        "### **Some helper classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mra4W_3zEOE8"
      },
      "source": [
        "#export\n",
        "class GraphGather(nn.Module):\n",
        "    r\"\"\"The GGNN readout function\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, node_features, out_features,\n",
        "                 att_depth=2, att_hidden_dim=100, att_dropout_p=0.0,\n",
        "                 emb_depth=2, emb_hidden_dim=100, emb_dropout_p=0.0):\n",
        "        super(GraphGather, self).__init__()\n",
        "\n",
        "        # denoted i and j in GGNN, MPNN and PotentialNet papers\n",
        "        self.att_nn = FeedForwardNetwork(\n",
        "            node_features * 2, [att_hidden_dim] * att_depth, out_features, dropout_p=att_dropout_p, bias=False\n",
        "        )\n",
        "        self.emb_nn = FeedForwardNetwork(\n",
        "            node_features, [emb_hidden_dim] * emb_depth, out_features, dropout_p=emb_dropout_p, bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, hidden_nodes, input_nodes, node_mask):\n",
        "        cat = torch.cat([hidden_nodes, input_nodes], dim=2)\n",
        "        energy_mask = (node_mask == 0).float() * 1e6\n",
        "        energies = self.att_nn(cat) - energy_mask.unsqueeze(-1)\n",
        "        attention = torch.sigmoid(energies)\n",
        "        #attention = torch.softmax(energies, dim=1)\n",
        "        embedding = self.emb_nn(hidden_nodes)\n",
        "        return torch.sum(attention * embedding, dim=1)\n",
        "\n",
        "\n",
        "class Set2Vec(nn.Module):\n",
        "    r\"\"\"The readout function of MPNN paper's best network\n",
        "    \"\"\"\n",
        "\n",
        "    # used to set attention terms to 0 when passing energies to softmax\n",
        "    # tf code uses same trick\n",
        "    BIG_NEGATIVE = -1e6\n",
        "\n",
        "    def __init__(self, node_features, lstm_computations, memory_size):\n",
        "        super(Set2Vec, self).__init__()\n",
        "\n",
        "        self.lstm_computations = lstm_computations\n",
        "        self.memory_size = memory_size\n",
        "\n",
        "        self.embedding_matrix = nn.Linear(node_features * 2, self.memory_size, bias=False)\n",
        "        self.lstm = nn.LSTMCell(self.memory_size, self.memory_size, bias=False)\n",
        "\n",
        "    def forward(self, hidden_output_nodes, input_nodes, node_mask):\n",
        "        #jj.append(node_mask)\n",
        "        #print(hidden_output_nodes)\n",
        "        #print(input_nodes)\n",
        "        batch_size = input_nodes.shape[0]\n",
        "        #print('HERE IS THE PROBLEM')\n",
        "        #print(node_mask)\n",
        "        #jj.append(node_mask)\n",
        "        energy_mask = (~node_mask).float() * self.BIG_NEGATIVE\n",
        "\n",
        "        lstm_input = torch.zeros(batch_size, self.memory_size)\n",
        "\n",
        "        cat = torch.cat([hidden_output_nodes, input_nodes], dim=2)\n",
        "        memory = self.embedding_matrix(cat)\n",
        "\n",
        "        hidden_state = torch.zeros(batch_size, self.memory_size)\n",
        "        cell_state = torch.zeros(batch_size, self.memory_size)\n",
        "\n",
        "        if next(self.parameters()).is_cuda:\n",
        "            lstm_input = lstm_input.cuda()\n",
        "            hidden_state = hidden_state.cuda()\n",
        "            cell_state = cell_state.cuda()\n",
        "\n",
        "        for i in range(self.lstm_computations):\n",
        "            query, cell_state = self.lstm(lstm_input, (hidden_state, cell_state))\n",
        "            # dot product query x memory\n",
        "            energies = (query.view(batch_size, 1, self.memory_size) * memory).sum(dim=-1)\n",
        "            attention = torch.softmax(energies + energy_mask, dim=1)\n",
        "            read = (attention.unsqueeze(-1) * memory).sum(dim=1)\n",
        "\n",
        "            hidden_state = query\n",
        "            lstm_input = read\n",
        "\n",
        "        cat = torch.cat([query, read], dim=1)\n",
        "        return cat\n",
        "\n",
        "\n",
        "class FeedForwardNetwork(nn.Module):\n",
        "    r\"\"\"Convenience class to create network composed of linear layers with an activation function\n",
        "    applied between them\n",
        "    Args:\n",
        "        in_features: size of each input sample\n",
        "        hidden_layer_sizes: list of hidden layer sizes\n",
        "        out_features: size of each output sample\n",
        "        activation: 'SELU' or 'ReLU'\n",
        "        bias: If set to False, the layers will not learn an additive bias.\n",
        "            Default: ``False``\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, hidden_layer_sizes, out_features, activation='SELU', bias=False, dropout_p=0.0):\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "\n",
        "        if activation == 'SELU':\n",
        "            Activation = nn.SELU\n",
        "            Dropout = nn.AlphaDropout\n",
        "            init_constant = 1.0\n",
        "        elif activation == 'ReLU':\n",
        "            Activation = nn.ReLU\n",
        "            Dropout = nn.Dropout\n",
        "            init_constant = 2.0\n",
        "\n",
        "        layer_sizes = [in_features] + hidden_layer_sizes + [out_features]\n",
        "\n",
        "        layers = []\n",
        "        for i in range(len(layer_sizes) - 2):\n",
        "            layers.append(Dropout(dropout_p))\n",
        "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1], bias))\n",
        "            layers.append(Activation())\n",
        "        layers.append(Dropout(dropout_p))\n",
        "        layers.append(nn.Linear(layer_sizes[-2], layer_sizes[-1], bias))\n",
        "\n",
        "        self.seq = nn.Sequential(*layers)\n",
        "\n",
        "        for i in range(1, len(layers), 3):\n",
        "            # initialization recommended in SELU paper\n",
        "            nn.init.normal_(layers[i].weight, std=math.sqrt(init_constant / layers[i].weight.size(1)))\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.seq(input)\n",
        "\n",
        "    # I'm probably *supposed to* override extra_repr but then self.seq (unreadable) will be printed too\n",
        "    def __repr__(self):\n",
        "        ffnn = type(self).__name__\n",
        "        in_features = self.seq[1].in_features\n",
        "        hidden_layer_sizes = [linear.out_features for linear in self.seq[1:-1:3]]\n",
        "        out_features = self.seq[-1].out_features\n",
        "        if len(self.seq) > 2:\n",
        "            activation = str(self.seq[2])\n",
        "        else:\n",
        "            activation = 'None'\n",
        "        bias = self.seq[1].bias is not None\n",
        "        dropout_p = self.seq[0].p\n",
        "        return '{}(in_features={}, hidden_layer_sizes={}, out_features={}, activation={}, bias={}, dropout_p={})'.format(\n",
        "            ffnn, in_features, hidden_layer_sizes, out_features, activation, bias, dropout_p\n",
        "        )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_mny1zKiFsn"
      },
      "source": [
        "### Summation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2AeL9mT9WUu"
      },
      "source": [
        "class SummationMPNN(Module):\n",
        "    r\"\"\"Abstract MPNN class, ExampleMPNN demonstrates how to extend it\n",
        "    Args:\n",
        "        node_features (int)\n",
        "        edge_features (int)\n",
        "        message_size (int)\n",
        "        message_passes (int)\n",
        "        out_features (int)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, node_features, edge_features, message_size, message_passes, out_features):\n",
        "        super(SummationMPNN, self).__init__()\n",
        "        self.node_features = node_features\n",
        "        self.edge_features = edge_features\n",
        "        self.message_size = message_size\n",
        "        self.message_passes = message_passes\n",
        "        self.out_features = out_features\n",
        "\n",
        "    # inputs are \"batches\" of shape (total number of edges in batch, number of features)\n",
        "    def message_terms(self, nodes, node_neighbours, edges):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # inputs are \"batches\" of shape (maximum number of nodes in batch, number of features)\n",
        "    def update(self, nodes, messages):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # inputs are \"batches\" of same shape as the nodes passed to update\n",
        "    # node_mask is same shape as inputs and is 1 if elements corresponding exists, otherwise 0\n",
        "    def readout(self, hidden_nodes, input_nodes, node_mask):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, x):\n",
        "        adjacency, nodes, edges = x\n",
        "        #print(adjacency,adjacency.shape)\n",
        "        #print(nodes,nodes.shape)\n",
        "        #print(edges,edges.shape)\n",
        "\n",
        "        edge_batch_batch_indices, edge_batch_node_indices, edge_batch_neighbour_indices = adjacency.nonzero().unbind(-1)\n",
        "        node_batch_batch_indices, node_batch_node_indices = adjacency.sum(-1).nonzero().unbind(-1)\n",
        "\n",
        "        same_batch = node_batch_batch_indices.view(-1, 1) == edge_batch_batch_indices\n",
        "        same_node = node_batch_node_indices.view(-1, 1) == edge_batch_node_indices\n",
        "        # element_ij = 1 if edge_batch_edges[j] is connected with node_batch_nodes[i], else 0\n",
        "        message_summation_matrix = (same_batch * same_node).float()\n",
        "\n",
        "        edge_batch_edges = edges[edge_batch_batch_indices, edge_batch_node_indices, edge_batch_neighbour_indices, :]\n",
        "        hidden_nodes = nodes.clone()\n",
        "        node_batch_nodes = hidden_nodes[node_batch_batch_indices, node_batch_node_indices, :]\n",
        "\n",
        "        for i in range(self.message_passes):\n",
        "            edge_batch_nodes = hidden_nodes[edge_batch_batch_indices, edge_batch_node_indices, :]\n",
        "            edge_batch_neighbours = hidden_nodes[edge_batch_batch_indices, edge_batch_neighbour_indices, :]\n",
        "\n",
        "            message_terms = self.message_terms(edge_batch_nodes, edge_batch_neighbours, edge_batch_edges)\n",
        "            # the summation in eq. 1 of the NMPQC paper happens here\n",
        "            messages = torch.matmul(message_summation_matrix, message_terms)\n",
        "            node_batch_nodes = self.update(node_batch_nodes, messages)\n",
        "\n",
        "            hidden_nodes[node_batch_batch_indices, node_batch_node_indices, :] = node_batch_nodes\n",
        "\n",
        "        node_mask = (adjacency.sum(-1) != 0)#.unsqueeze(-1).expand_as(nodes)\n",
        "        output = self.readout(hidden_nodes, nodes, node_mask)\n",
        "        return output\n",
        "        \n",
        "\n",
        "((sample_adjacency, sample_nodes, sample_edges), sample_target) = train_ds[0]\n",
        "\n",
        "class ENNS2V(SummationMPNN):\n",
        "\n",
        "    def __init__(self, node_features=len(sample_nodes[0]), edge_features=len(sample_edges[0, 0]), message_size=50,\n",
        "                 message_passes=5, out_features=1,\n",
        "                 enn_depth=4, enn_hidden_dim=200, enn_dropout_p=0,\n",
        "                 s2v_lstm_computations=12, s2v_memory_size=50,\n",
        "                 out_depth=1, out_hidden_dim=200, out_dropout_p=0):\n",
        "        super(ENNS2V, self).__init__(node_features, edge_features, message_size, message_passes, out_features)\n",
        "\n",
        "        self.enn = FeedForwardNetwork(\n",
        "            edge_features, [enn_hidden_dim] * enn_depth, node_features * message_size, dropout_p=enn_dropout_p\n",
        "        )\n",
        "        self.gru = nn.GRUCell(input_size=message_size, hidden_size=node_features, bias=False) # What if we used a fine-tuned LSTM/GRU here? Maybe transfer learning + ULMFit?\n",
        "        self.s2v = Set2Vec(node_features, s2v_lstm_computations, s2v_memory_size)\n",
        "        self.out_nn = FeedForwardNetwork(\n",
        "            s2v_memory_size * 2, [out_hidden_dim] * out_depth, out_features, dropout_p=out_dropout_p, bias=False\n",
        "        )\n",
        "\n",
        "    def message_terms(self, nodes, node_neighbours, edges):\n",
        "        enn_output = self.enn(edges)\n",
        "        matrices = enn_output.view(-1, self.message_size, self.node_features)\n",
        "        msg_terms = torch.matmul(matrices, node_neighbours.unsqueeze(-1)).squeeze(-1)\n",
        "        return msg_terms\n",
        "\n",
        "    def update(self, nodes, messages):\n",
        "        return self.gru(messages, nodes)\n",
        "\n",
        "    def readout(self, hidden_nodes, input_nodes, node_mask):\n",
        "        graph_embeddings = self.s2v(hidden_nodes, input_nodes, node_mask)\n",
        "        return self.out_nn(graph_embeddings)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxZLB6eAh2zq"
      },
      "source": [
        "### EMNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPKSO6Kyh7nN"
      },
      "source": [
        "class EMN(nn.Module):\n",
        "\n",
        "    def __init__(self, edge_features, edge_embedding_size, message_passes, out_features):\n",
        "        super(EMN, self).__init__()\n",
        "        self.edge_features = edge_features\n",
        "        self.edge_embedding_size = edge_embedding_size\n",
        "        self.message_passes = message_passes\n",
        "        self.out_features = out_features\n",
        "\n",
        "    def preprocess_edges(self, nodes, node_neighbours, edges):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # (total number of edges in batch, edge_features) and (total number of edges in batch, max_node_degree, edge_features)\n",
        "    def propagate_edges(self, edges, ingoing_edge_memories, ingoing_edges_mask):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def readout(self, hidden_nodes, input_nodes, node_mask):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    # adjacency (N, n_nodes, n_nodes); edges (N, n_nodes, n_nodes, edge_features)\n",
        "    def forward(self, x):\n",
        "        adjacency, nodes, edges = x\n",
        "        # indices for finding edges in batch\n",
        "        edges_b_idx, edges_n_idx, edges_nhb_idx = adjacency.nonzero().unbind(-1)\n",
        "\n",
        "        n_edges = edges_n_idx.shape[0]\n",
        "        adj_of_edge_batch_indices = adjacency.clone().long()\n",
        "        r = torch.arange(n_edges) + 1  # +1 to distinguish the index 0 from 'empty' elements, subtracted few lines down\n",
        "        if next(self.parameters()).is_cuda:\n",
        "            r = r.cuda()\n",
        "        adj_of_edge_batch_indices[edges_b_idx, edges_n_idx, edges_nhb_idx] = r\n",
        "\n",
        "        ingoing_edges_eb_idx = (torch.cat([\n",
        "            row[row.nonzero()] for row in adj_of_edge_batch_indices[edges_b_idx, edges_nhb_idx, :]\n",
        "        ]) - 1).squeeze()\n",
        "\n",
        "        edge_degrees = adjacency[edges_b_idx, edges_nhb_idx, :].sum(-1).long()\n",
        "        ingoing_edges_igeb_idx = torch.cat([i * torch.ones(d) for i, d in enumerate(edge_degrees)]).long()\n",
        "        ingoing_edges_ige_idx = torch.cat([torch.arange(i) for i in edge_degrees]).long()\n",
        "\n",
        "        batch_size = adjacency.shape[0]\n",
        "        n_nodes = adjacency.shape[1]\n",
        "        max_node_degree = adjacency.sum(-1).max().int()\n",
        "        edge_memories = torch.zeros(n_edges, self.edge_embedding_size)\n",
        "        ingoing_edge_memories = torch.zeros(n_edges, max_node_degree, self.edge_embedding_size)\n",
        "        ingoing_edges_mask = torch.zeros(n_edges, max_node_degree)\n",
        "        if next(self.parameters()).is_cuda:\n",
        "            edge_memories = edge_memories.cuda()\n",
        "            ingoing_edge_memories = ingoing_edge_memories.cuda()\n",
        "            ingoing_edges_mask = ingoing_edges_mask.cuda()\n",
        "\n",
        "        edge_batch_nodes = nodes[edges_b_idx, edges_n_idx, :]\n",
        "        edge_batch_neighbours = nodes[edges_b_idx, edges_nhb_idx, :]\n",
        "        edge_batch_edges = edges[edges_b_idx, edges_n_idx, edges_nhb_idx, :]\n",
        "        edge_batch_edges = self.preprocess_edges(edge_batch_nodes, edge_batch_neighbours, edge_batch_edges)\n",
        "\n",
        "        # remove h_ji:s influence on h_ij\n",
        "        ingoing_edges_nhb_idx = edges_nhb_idx[ingoing_edges_eb_idx]\n",
        "        ingoing_edges_receiving_edge_n_idx = edges_n_idx[ingoing_edges_igeb_idx]\n",
        "        not_same_idx = (ingoing_edges_receiving_edge_n_idx != ingoing_edges_nhb_idx).nonzero()\n",
        "        ingoing_edges_eb_idx = ingoing_edges_eb_idx[not_same_idx].squeeze()\n",
        "        ingoing_edges_ige_idx = ingoing_edges_ige_idx[not_same_idx].squeeze()\n",
        "        ingoing_edges_igeb_idx = ingoing_edges_igeb_idx[not_same_idx].squeeze()\n",
        "\n",
        "        ingoing_edges_mask[ingoing_edges_igeb_idx, ingoing_edges_ige_idx] = 1\n",
        "\n",
        "        for i in range(self.message_passes):\n",
        "            ingoing_edge_memories[ingoing_edges_igeb_idx, ingoing_edges_ige_idx, :] = \\\n",
        "                edge_memories[ingoing_edges_eb_idx, :]\n",
        "            edge_memories = self.propagate_edges(edge_batch_edges, ingoing_edge_memories.clone(), ingoing_edges_mask)\n",
        "\n",
        "        node_mask = (adjacency.sum(-1) != 0)\n",
        "\n",
        "        node_sets = torch.zeros(batch_size, n_nodes, max_node_degree, self.edge_embedding_size)\n",
        "        if next(self.parameters()).is_cuda:\n",
        "            node_sets = node_sets.cuda()\n",
        "\n",
        "        edge_batch_edge_memory_indices = torch.cat(\n",
        "            [torch.arange(row.sum()) for row in adjacency.view(-1, n_nodes)]\n",
        "        ).long()\n",
        "\n",
        "        node_sets[edges_b_idx, edges_n_idx, edge_batch_edge_memory_indices, :] = edge_memories\n",
        "        graph_sets = node_sets.sum(2)\n",
        "        output = self.readout(graph_sets, graph_sets, node_mask)\n",
        "\n",
        "        return sigmoid_range(output, low=1,high=12.5)\n",
        "\n",
        "class EMNImplementation(EMN):\n",
        "\n",
        "    def __init__(self, node_features=len(sample_nodes[0]), edge_features=len(sample_edges[0, 0]), message_passes=8, out_features=1,\n",
        "                 edge_embedding_size=50,\n",
        "                 edge_emb_depth=3, edge_emb_hidden_dim=150, edge_emb_dropout_p=0.5,\n",
        "                 att_depth=3, att_hidden_dim=80, att_dropout_p=0.5,\n",
        "                 msg_depth=3, msg_hidden_dim=80, msg_dropout_p=0.5,\n",
        "                 gather_width=100,\n",
        "                 gather_att_depth=3, gather_att_hidden_dim=26, gather_att_dropout_p=0.5,\n",
        "                 gather_emb_depth=3, gather_emb_hidden_dim=26, gather_emb_dropout_p=0.5,\n",
        "                 out_depth=2, out_hidden_dim=360, out_dropout_p=0.5, out_layer_shrinkage=0.25):\n",
        "        super(EMNImplementation, self).__init__(\n",
        "            edge_features, edge_embedding_size, message_passes, out_features\n",
        "        )\n",
        "        self.embedding_nn = FeedForwardNetwork(\n",
        "            node_features * 2 + edge_features, [edge_emb_hidden_dim] * edge_emb_depth, edge_embedding_size, dropout_p=edge_emb_dropout_p\n",
        "        )\n",
        "\n",
        "        self.emb_msg_nn = FeedForwardNetwork(\n",
        "            edge_embedding_size, [msg_hidden_dim] * msg_depth, edge_embedding_size, dropout_p=msg_dropout_p\n",
        "        )\n",
        "        self.att_msg_nn = FeedForwardNetwork(\n",
        "            edge_embedding_size, [att_hidden_dim] * att_depth, edge_embedding_size, dropout_p=att_dropout_p\n",
        "        )\n",
        "\n",
        "        #self.extra_gru_layer = nn.Linear(edge_embedding_size, edge_embedding_size, bias=False)\n",
        "        self.gru = nn.GRUCell(edge_embedding_size, edge_embedding_size, bias=False)\n",
        "        self.gather = GraphGather(\n",
        "            edge_embedding_size, gather_width,\n",
        "            gather_att_depth, gather_att_hidden_dim, gather_att_dropout_p,\n",
        "            gather_emb_depth, gather_emb_hidden_dim, gather_emb_dropout_p\n",
        "        )\n",
        "        out_layer_sizes = [  # example: depth 5, dim 50, shrinkage 0.5 => out_layer_sizes [50, 42, 35, 30, 25]\n",
        "            round(out_hidden_dim * (out_layer_shrinkage ** (i / (out_depth - 1 + 1e-9)))) for i in range(out_depth)\n",
        "        ]\n",
        "        self.out_nn = FeedForwardNetwork(gather_width, out_layer_sizes, out_features, dropout_p=out_dropout_p)\n",
        "\n",
        "    def preprocess_edges(self, nodes, node_neighbours, edges):\n",
        "        cat = torch.cat([nodes, node_neighbours, edges], dim=1)\n",
        "        return torch.tanh(self.embedding_nn(cat))\n",
        "\n",
        "    def propagate_edges(self, edges, ingoing_edge_memories, ingoing_edges_mask):\n",
        "        BIG_NEGATIVE = -1e6\n",
        "        energy_mask = ((1 - ingoing_edges_mask).float() * BIG_NEGATIVE).unsqueeze(-1)\n",
        "\n",
        "        cat = torch.cat([edges.unsqueeze(1), ingoing_edge_memories], dim=1)\n",
        "        embeddings = self.emb_msg_nn(cat)\n",
        "\n",
        "        edge_energy = self.att_msg_nn(edges)\n",
        "        ing_memory_energies = self.att_msg_nn(ingoing_edge_memories) + energy_mask\n",
        "        energies = torch.cat([edge_energy.unsqueeze(1), ing_memory_energies], dim=1)\n",
        "        attention = torch.softmax(energies, dim=1)\n",
        "\n",
        "        # set aggregation of the set of the given edge feature and ingoing edge memories\n",
        "        message = (attention * embeddings).sum(dim=1)\n",
        "        return self.gru(message)  # returning hidden state but it is also set internally I think.. hm\n",
        "\n",
        "    def readout(self, hidden_nodes, input_nodes, node_mask):\n",
        "        graph_embeddings = self.gather(hidden_nodes, input_nodes, node_mask)\n",
        "        return self.out_nn(graph_embeddings)    \n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkaWXvdLYmbh"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7upcQlq4wuk"
      },
      "source": [
        "model = EMNImplementation()\n",
        "learn = Learner(dls, model,loss_func=MSELossFlat(),metrics=[mse,rmse,PearsonCorrCoef(),R2Score()])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4WwEXNnEtOe",
        "outputId": "d1fe649b-0e02-4db8-9075-12f5f65ccfc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>mse</th>\n",
              "      <th>_rmse</th>\n",
              "      <th>pearsonr</th>\n",
              "      <th>r2_score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "EMNImplementation (Input shape: [\"['64 x 45 x 45', '64 x 45 x 75', '64 x 45 x 45 x 4']\"])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "AlphaDropout         64 x 154             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 150             23,100     True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 150             0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 150             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 150             22,500     True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 150             0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 150             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 150             22,500     True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 150             0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 150             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 50              7,500      True      \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 5 x 50          0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 5 x 80          4,000      True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 5 x 80          0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 5 x 80          0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 5 x 80          6,400      True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 5 x 80          0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 5 x 80          0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 5 x 80          6,400      True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 5 x 80          0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 5 x 80          0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 5 x 50          4,000      True      \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 4 x 50          0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 4 x 80          4,000      True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 4 x 80          0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 4 x 80          0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 4 x 80          6,400      True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 4 x 80          0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 4 x 80          0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 4 x 80          6,400      True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 4 x 80          0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 4 x 80          0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 4 x 50          4,000      True      \n",
              "________________________________________________________________\n",
              "GRUCell              64 x 50              15,000     True      \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 45 x 100        0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 45 x 26         2,600      True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 45 x 26         676        True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 45 x 26         676        True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 45 x 100        2,600      True      \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 45 x 50         0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 45 x 26         1,300      True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 45 x 26         676        True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 45 x 26         676        True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 45 x 26         0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 45 x 100        2,600      True      \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 100             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 360             36,000     True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 360             0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 360             0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 90              32,400     True      \n",
              "________________________________________________________________\n",
              "SELU                 64 x 90              0          False     \n",
              "________________________________________________________________\n",
              "AlphaDropout         64 x 90              0          False     \n",
              "________________________________________________________________\n",
              "Linear               64 x 1               90         True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 212,494\n",
              "Total trainable params: 212,494\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7f6d94da1620>\n",
              "Loss function: FlattenedLoss of MSELoss()\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO3dzksZ5ip6",
        "outputId": "98fa63e2-9dab-41f0-eaf3-702a2474c163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "learn.lr_find(num_it=300)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=0.007822279632091523, lr_steep=0.013182567432522774)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2j-ZmTe6j8c",
        "outputId": "28bd82a2-a2d6-4d67-e229-84739ffc6dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "learn.fit(10, 1e-2,cbs=[CSVLogger(),SaveModelCallback(monitor='_rmse')])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>mse</th>\n",
              "      <th>_rmse</th>\n",
              "      <th>pearsonr</th>\n",
              "      <th>r2_score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.127880</td>\n",
              "      <td>22.193836</td>\n",
              "      <td>22.193836</td>\n",
              "      <td>4.711033</td>\n",
              "      <td>0.059545</td>\n",
              "      <td>-12.026518</td>\n",
              "      <td>01:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.166198</td>\n",
              "      <td>2.128343</td>\n",
              "      <td>2.128343</td>\n",
              "      <td>1.458884</td>\n",
              "      <td>0.006413</td>\n",
              "      <td>-0.249216</td>\n",
              "      <td>01:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.432171</td>\n",
              "      <td>2.679850</td>\n",
              "      <td>2.679850</td>\n",
              "      <td>1.637025</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.572919</td>\n",
              "      <td>01:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.061330</td>\n",
              "      <td>1.825929</td>\n",
              "      <td>1.825929</td>\n",
              "      <td>1.351269</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.071716</td>\n",
              "      <td>01:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.908947</td>\n",
              "      <td>1.820148</td>\n",
              "      <td>1.820148</td>\n",
              "      <td>1.349128</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.068323</td>\n",
              "      <td>01:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.825987</td>\n",
              "      <td>1.722799</td>\n",
              "      <td>1.722799</td>\n",
              "      <td>1.312554</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.011185</td>\n",
              "      <td>01:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.901904</td>\n",
              "      <td>1.867002</td>\n",
              "      <td>1.867002</td>\n",
              "      <td>1.366383</td>\n",
              "      <td>-0.226268</td>\n",
              "      <td>-0.095824</td>\n",
              "      <td>01:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.849740</td>\n",
              "      <td>1.730385</td>\n",
              "      <td>1.730385</td>\n",
              "      <td>1.315441</td>\n",
              "      <td>-0.183529</td>\n",
              "      <td>-0.015638</td>\n",
              "      <td>01:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.869812</td>\n",
              "      <td>1.769007</td>\n",
              "      <td>1.769007</td>\n",
              "      <td>1.330040</td>\n",
              "      <td>0.110690</td>\n",
              "      <td>-0.038306</td>\n",
              "      <td>01:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.826283</td>\n",
              "      <td>2.793274</td>\n",
              "      <td>2.793274</td>\n",
              "      <td>1.671309</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.639493</td>\n",
              "      <td>01:19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with pearsonr value: 0.05954522235407967.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 8 with pearsonr value: 0.11068970667762301.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXVxkHRFJ13K",
        "outputId": "f40916ef-da25-4257-d503-cca1a844e55e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "learn.save('fit1')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/fit1.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV22cESgKSd1"
      },
      "source": [
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}